{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "372580d5-6d0e-43af-907d-9224c6815d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f5d8336-ca2e-40a1-9514-82242a3e418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt') # pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be71b7a7-2564-4d5f-8ea6-46e83ce3a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\cbamm\\1 Jupyter\\SD\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 96.3ms\n",
      "Speed: 5.2ms preprocess, 96.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results_bus.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model('bus.jpg')      # or any image\n",
    "results[0].show()               # display annotated image\n",
    "results[0].save()               # save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ef73327-33cf-4849-ae40-dfd4c3444523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.]) tensor([0.8734])\n",
      "tensor([0.]) tensor([0.8657])\n",
      "tensor([0.]) tensor([0.8528])\n",
      "tensor([0.]) tensor([0.8252])\n"
     ]
    }
   ],
   "source": [
    "for box in results[0].boxes:\n",
    "    if box.conf > 0.5:  # only keep strong detections\n",
    "        print(box.cls, box.conf)\n",
    "# tensor([class_id]) tensor([confidence_score])\n",
    "# class 0 = person\n",
    "# class 5 = bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cd2e4a2-61a8-4ff1-9dbd-85740124a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus: 0.87\n",
      "person: 0.87\n",
      "person: 0.85\n",
      "person: 0.83\n",
      "person: 0.26\n",
      "stop sign: 0.26\n"
     ]
    }
   ],
   "source": [
    "for box in results[0].boxes:\n",
    "    cls = int(box.cls)\n",
    "    conf = float(box.conf)\n",
    "    label = model.names[cls]\n",
    "    print(f\"{label}: {conf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dfa88f3-f910-4b23-99d8-08707ca31ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\cbamm\\1 Jupyter\\SD\\bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 173.1ms\n",
      "Speed: 3.8ms preprocess, 173.1ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Segmentation\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "results = model('bus.jpg')\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eac8907b-7acb-4d7e-bfff-88c0140c8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 0.88\n",
      "person: 0.86\n",
      "person: 0.84\n",
      "bus: 0.84\n",
      "person: 0.41\n",
      "skateboard: 0.39\n"
     ]
    }
   ],
   "source": [
    "for box in results[0].boxes:\n",
    "    cls = int(box.cls)\n",
    "    conf = float(box.conf)\n",
    "    label = model.names[cls]\n",
    "    print(f\"{label}: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ed9fc5e-8870-425c-b569-7282148da119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-seg.pt to 'yolov8m-seg.pt': 100% ━━━━━━━━━━━━ 52.4MB 6.7MB/s 7.8s 7.8s<0.0s3s\n",
      "\n",
      "0: 640x640 (no detections), 600.9ms\n",
      "1: 640x640 1 truck, 600.9ms\n",
      "2: 640x640 1 truck, 600.9ms\n",
      "Speed: 4.6ms preprocess, 600.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8m-seg.pt') # loads pretrained LARGE segmentation model\n",
    "results = model(['door1.jpg', 'door2.jpg', 'door3.jpg'])\n",
    "for box in results[0].boxes:\n",
    "    cls = int(box.cls)\n",
    "    conf = float(box.conf)\n",
    "    label = model.names[cls]\n",
    "    print(f\"{label}: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24fb8398-0ae9-485b-87ce-7d7aaf8481b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6154263b-0717-4c11-a16a-ea7fa0989703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data set of 10 labeled imgages 8/1/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72731aae-71b1-48f3-acdf-99ddeea5609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r'C:\\Users\\cbamm\\OneDrive\\Documents\\[1] UNCC\\Coursework\\7 Fall 2025\\ECGR 4251\\Dataset\\Truck Segmentation.v1-v1.yolov8\\data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043759a-0b07-4ad1-8787-748861eefe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "model.train(\n",
    "    data=r'C:\\Users\\cbamm\\Downloads\\Truck Segmentation.v1-v1.yolov8\\data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    task='segment'\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3f62ad-84df-45f5-87db-bc4ff6d82658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door11.jpg: 480x640 (no detections), 136.7ms\n",
      "image 2/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door12.jpg: 480x640 (no detections), 115.9ms\n",
      "image 3/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door13.jpg: 480x640 1 door, 139.2ms\n",
      "image 4/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door14.jpg: 480x640 1 door, 128.2ms\n",
      "image 5/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door15.jpg: 640x640 1 door, 185.0ms\n",
      "image 6/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door16.jpg: 640x640 1 door, 177.0ms\n",
      "image 7/7 C:\\Users\\cbamm\\Downloads\\unlabeled\\door17.jpg: 640x640 2 doors, 185.3ms\n",
      "Speed: 3.5ms preprocess, 152.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\cbamm\\1 Jupyter\\Senior Design 1\\runs\\segment\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('runs/segment/train5/weights/best.pt')  # path to your trained model\n",
    "results = model.predict(source=r'C:\\Users\\cbamm\\Downloads\\unlabeled', save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a99153-793e-4b2a-9921-fce359c36c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1: C:\\Users\\cbamm\\Downloads\\unlabeled\\door11.jpg\n",
      "No detections\n",
      "\n",
      "Image 2: C:\\Users\\cbamm\\Downloads\\unlabeled\\door12.jpg\n",
      "No detections\n",
      "\n",
      "Image 3: C:\\Users\\cbamm\\Downloads\\unlabeled\\door13.jpg\n",
      "  Class: door, Confidence: 0.44\n",
      "\n",
      "Image 4: C:\\Users\\cbamm\\Downloads\\unlabeled\\door14.jpg\n",
      "  Class: door, Confidence: 0.36\n",
      "\n",
      "Image 5: C:\\Users\\cbamm\\Downloads\\unlabeled\\door15.jpg\n",
      "  Class: door, Confidence: 0.78\n",
      "\n",
      "Image 6: C:\\Users\\cbamm\\Downloads\\unlabeled\\door16.jpg\n",
      "  Class: door, Confidence: 0.59\n",
      "\n",
      "Image 7: C:\\Users\\cbamm\\Downloads\\unlabeled\\door17.jpg\n",
      "  Class: door, Confidence: 0.70\n",
      "  Class: door, Confidence: 0.40\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(results):\n",
    "    print(f\"\\nImage {i+1}: {r.path}\")\n",
    "    if len(r.boxes) == 0:\n",
    "        print(\"No detections\")\n",
    "    else:\n",
    "        for c, conf in zip(r.boxes.cls, r.boxes.conf):\n",
    "            print(f\"  Class: {model.names[int(c)]}, Confidence: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cd9f0-2c8d-474c-a438-e351c04ef389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
